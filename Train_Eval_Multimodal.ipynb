{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82b7a041-fae1-4288-abed-c514ea8b1260",
   "metadata": {},
   "source": [
    "# Weight Technique 3: Multimodal Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfeb8c4c-5338-4471-8909-13b9fe7a0b88",
   "metadata": {},
   "source": [
    "Multimodal weights are a technique used in deep learning to combine information from multiple sources (modalities) to enhance model performance. In the context of MedLM, this means leveraging data from different types of medical information, such as:\n",
    "Text: Medical records and patient notes from MIMIC IV dataset\n",
    "\n",
    "- Feature Extraction: Each modality is processed separately to extract meaningful features. For example: Text: Word embeddings, sentence embeddings, or other text-based features.\n",
    "- Feature Fusion: The extracted features from different modalities are combined into a single representation. This can be done using techniques like:\n",
    "1. Concatenation: Simply combining the feature vectors from each modality.\n",
    "2. Attention Mechanisms: Learning to focus on the most relevant features from each modality.\n",
    "- Model Training: The combined multimodal features are used to train the MedLM model. The model learns to associate these features with the desired output (e.g., diagnosis, treatment recommendations).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a8f2307-ac45-4ba4-be65-6b60a13daaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud.aiplatform.gapic.schema import predict\n",
    "from google.protobuf import json_format\n",
    "from google.protobuf.struct_pb2 import Value\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from google.cloud import bigquery\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_experimental.sql import SQLDatabaseChain\n",
    "from langchain.sql_database import SQLDatabase\n",
    "from langchain.prompts import PromptTemplate\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88c3f808-900b-470f-9e2b-bf0d729c347d",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_api_key = openai_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f69cf499-fcbd-4268-944c-cf60e3ca7a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated SQL: subject_id\thadm_id\tdrug\n",
      "10000032\t22595853\tAspirin\n",
      "10000032\t22595853\tIbuprofen\n",
      "\n",
      "Answer: The medication prescribed to patients treated for post op includes Aspirin and Ibuprofen.\n"
     ]
    }
   ],
   "source": [
    "# Initialize BigQuery client\n",
    "bigquery_client = bigquery.Client()\n",
    "\n",
    "# Define the Gemini model\n",
    "llm = ChatOpenAI(openai_api_key=openai_api_key, model=\"gpt-4-32k\")\n",
    "\n",
    "# Manually define the SQLDatabase\n",
    "# Assume you have a BigQuery connection string or credentials file\n",
    "connection_string = \"bigquery://us-gcp-ame-con-5b680-sbx-1/mimic_iv_hosp_icu_dataset\"\n",
    "\n",
    "# Create the SQLDatabase instance\n",
    "db = SQLDatabase.from_uri(connection_string)\n",
    "\n",
    "# Create the SQLDatabaseChain\n",
    "chain = SQLDatabaseChain(llm=llm, database=db)\n",
    "\n",
    "# Define your natural language query\n",
    "natural_language_query = \"List of medication prescribed to patients treated for post op limit 2\"\n",
    "\n",
    "# Generate SQL and execute\n",
    "sql_query = chain.run(natural_language_query)\n",
    "print(\"Generated SQL:\", sql_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef75fa04-adc2-42bf-873a-6c0d7243eb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f8214254-7195-471f-96b7-5ab2514fb775",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Aspirin and ibuprofen are both nonsteroidal anti-inflammatory drugs (NSAIDs) that are commonly used to relieve pain and inflammation. They work by blocking the production of prostaglandins, which are chemicals that are involved in the inflammatory response. Aspirin is a salicylate, while ibuprofen is a propionic acid derivative. Both drugs are available over-the-counter and by prescription. Aspirin is typically used for short-term pain relief, while ibuprofen can be used for both short-term and long-term pain management. In addition to their analgesic and anti-inflammatory effects, aspirin and ibuprofen can also have other effects on the body. For example, aspirin can inhibit platelet aggregation, which is why it is sometimes used to prevent blood clots. Ibuprofen can also have effects on the kidneys and gastrointestinal tract. It is important to follow the dosing instructions on the medication label and to talk to your doctor or pharmacist if you have any questions or concerns about aspirin or ibuprofen.\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from google.cloud import aiplatform\n",
    "from google.protobuf import json_format\n",
    "from google.protobuf.json_format import MessageToDict\n",
    "from google.protobuf.struct_pb2 import Value\n",
    "\n",
    "client_options = {\"api_endpoint\": \"us-central1-aiplatform.googleapis.com\"}\n",
    "\n",
    "# Initialize client that will be used to create and send requests.\n",
    "\n",
    "# This client only needs to be created once, and can be reused for multiple requests.\n",
    "\n",
    "client = aiplatform.gapic.PredictionServiceClient(\n",
    "\n",
    "    client_options=client_options\n",
    "\n",
    ")\n",
    "\n",
    "# Define the MedLM endpoint\n",
    "endpoint = \"projects/us-gcp-ame-con-5b680-sbx-1/locations/us-central1/publishers/google/models/medlm-large\"\n",
    "\n",
    "# Example reference text\n",
    "reference_text = 'The medication prescribed to patients treated for post op includes Aspirin and Ibuprofen'\n",
    "\n",
    "# Prepare the instance for prediction\n",
    "instance_dict = {\"content\": reference_text}\n",
    "instance = json_format.ParseDict(instance_dict, Value())\n",
    "instances = [instance]\n",
    "\n",
    "# Define parameters for the MedLM model (optional)\n",
    "parameters_dict = {\n",
    "     \"candidateCount\": 1,\n",
    "     \"maxOutputTokens\": 500,\n",
    "     \"temperature\": 0.2,\n",
    "     \"topP\": 0.8,\n",
    "     \"topK\": 40\n",
    "}\n",
    "\n",
    "\n",
    "parameters = json_format.ParseDict(parameters_dict, Value())\n",
    "# Send the prediction request to MedLM\n",
    "response = client.predict(endpoint=endpoint, instances=instances, parameters=parameters)\n",
    "\n",
    "# Extract the encoded features from the MedLM response\n",
    "encoded_reference = response.predictions\n",
    "\n",
    "for prediction in encoded_reference:\n",
    "    embeddings = prediction.get('content', None)\n",
    "    # Check if embeddings were found\n",
    "    if embeddings is not None:\n",
    "        # Convert the embeddings to a NumPy array\n",
    "        features = np.array(embeddings)\n",
    "        print(features)\n",
    "    else:\n",
    "        print(\"Embeddings not found in the response.\")\n",
    "\n",
    "\n",
    "print(type(features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9225cfca-49a3-4ccf-968f-37d228dbd39b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e4ac057c-68fa-4fb6-8259-02941a59accf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.0000e+00 - loss: 1007.7798\n",
      "Epoch 2/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.0000e+00 - loss: 997.7004\n",
      "Epoch 3/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.0000e+00 - loss: 986.8818\n",
      "Epoch 4/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.0000e+00 - loss: 973.7292\n",
      "Epoch 5/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.0000e+00 - loss: 955.9148\n",
      "Epoch 6/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.0000e+00 - loss: 929.0397\n",
      "Epoch 7/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.0000e+00 - loss: 885.1016\n",
      "Epoch 8/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.0000e+00 - loss: 821.2887\n",
      "Epoch 9/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.0000e+00 - loss: 753.4536\n",
      "Epoch 10/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.0000e+00 - loss: 694.0807\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f7274118ee0>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "\n",
    "# Example text data\n",
    "text_data = 'Aspirin and ibuprofen are both nonsteroidal anti-inflammatory drugs (NSAIDs) that are commonly used to relieve pain and inflammation. They work by blocking the production of prostaglandins, which are chemicals that are involved in the inflammatory response. Aspirin is a salicylate, while ibuprofen is a propionic acid derivative. Both drugs are available over-the-counter and by prescription. Aspirin is typically used for short-term pain relief, while ibuprofen can be used for both short-term and long-term pain management. In addition to their analgesic and anti-inflammatory effects, aspirin and ibuprofen can also have other effects on the body. For example, aspirin can inhibit platelet aggregation, which is why it is sometimes used to prevent blood clots. Ibuprofen can also have effects on the kidneys and gastrointestinal tract. It is important to follow the dosing instructions on the medication label and to talk to your doctor or pharmacist if you have any questions or concerns about aspirin or ibuprofen.'\n",
    "\n",
    "# Convert text data to numerical features using TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=100)  # Limit to top 100 features for simplicity\n",
    "features = vectorizer.fit_transform([text_data]).toarray().flatten()  # Convert to 1D array\n",
    "\n",
    "# Define model parameters\n",
    "max_length = 100  # Define max_length\n",
    "vocab_size = 5000  # Example vocab size, adjust as needed\n",
    "embedding_dim = 128  # Define embedding_dim\n",
    "\n",
    "# Create the model\n",
    "def create_model(max_length, feature_dim):\n",
    "    input_text = tf.keras.Input(shape=(max_length,), dtype=\"int32\")\n",
    "    reference_features = tf.keras.Input(shape=(feature_dim,))\n",
    "\n",
    "    # Embed the input text\n",
    "    embedded_text = Embedding(vocab_size, embedding_dim)(input_text)\n",
    "\n",
    "    # Process the input text using an LSTM\n",
    "    lstm_output = LSTM(128)(embedded_text)\n",
    "\n",
    "    # Concatenate the LSTM output with the reference features\n",
    "    combined_features = tf.keras.layers.concatenate([lstm_output, reference_features])\n",
    "\n",
    "    # Add a dense layer for summarization\n",
    "    summary = Dense(max_length, activation=\"softmax\")(combined_features)\n",
    "\n",
    "    return tf.keras.Model(inputs=[input_text, reference_features], outputs=summary)\n",
    "\n",
    "# Calculate feature dimension\n",
    "feature_dim = features.shape[0]\n",
    "\n",
    "# Create the model\n",
    "model = create_model(max_length, feature_dim)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Example input text and reference text for training\n",
    "input_texts = [\n",
    "    'The medication prescribed to patients treated for post op includes Aspirin and Ibuprofen.',\n",
    "    'Aspirin and ibuprofen are used to relieve pain and inflammation.'\n",
    "]\n",
    "reference_text = 'Aspirin and ibuprofen are both nonsteroidal anti-inflammatory drugs (NSAIDs) that are commonly used to relieve pain and inflammation. They work by blocking the production of prostaglandins, which are chemicals that are involved in the inflammatory response. Aspirin is a salicylate, while ibuprofen is a propionic acid derivative. Both drugs are available over-the-counter and by prescription. Aspirin is typically used for short-term pain relief, while ibuprofen can be used for both short-term and long-term pain management. In addition to their analgesic and anti-inflammatory effects, aspirin and ibuprofen can also have other effects on the body. For example, aspirin can inhibit platelet aggregation, which is why it is sometimes used to prevent blood clots. Ibuprofen can also have effects on the kidneys and gastrointestinal tract. It is important to follow the dosing instructions on the medication label and to talk to your doctor or pharmacist if you have any questions or concerns about aspirin or ibuprofen.'\n",
    "\n",
    "# Tokenize the texts\n",
    "tokenizer = Tokenizer(num_words=vocab_size)\n",
    "tokenizer.fit_on_texts(input_texts + [reference_text])\n",
    "\n",
    "# Convert texts to sequences\n",
    "input_sequences = tokenizer.texts_to_sequences(input_texts)\n",
    "reference_sequence = tokenizer.texts_to_sequences([reference_text])[0]\n",
    "\n",
    "# Pad the sequences\n",
    "input_text_data = pad_sequences(input_sequences, maxlen=max_length, padding='post')\n",
    "reference_features_data = np.tile(features, (len(input_texts), 1))\n",
    "\n",
    "# Prepare target text data (example)\n",
    "target_texts = [\n",
    "    \"Aspirin and ibuprofen are NSAIDs used for pain relief.\",\n",
    "    \"Both drugs are available over-the-counter and by prescription.\"\n",
    "]\n",
    "target_sequences = tokenizer.texts_to_sequences(target_texts)\n",
    "target_text_data = pad_sequences(target_sequences, maxlen=max_length, padding='post')  # No one-hot encoding\n",
    "\n",
    "# Fit the model\n",
    "model.fit(\n",
    "    [input_text_data, reference_features_data],\n",
    "    target_text_data,\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50030e88-2764-4b29-9485-662dd8578ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the Note iv data set for test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cbc598a1-16d5-4751-b81b-7e122db71053",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated SQL: The two medications in the discharge texts where patients are treated for post op are CHF and critical aortic stenosis for the first patient and Vioxx for the second patient.\n"
     ]
    }
   ],
   "source": [
    "# Initialize BigQuery client\n",
    "bigquery_client = bigquery.Client()\n",
    "\n",
    "# Define the Gemini model\n",
    "llm = ChatOpenAI(openai_api_key=openai_api_key, model=\"gpt-4-32k\")\n",
    "\n",
    "# Manually define the SQLDatabase\n",
    "# Assume you have a BigQuery connection string or credentials file\n",
    "connection_string = \"bigquery://us-gcp-ame-con-5b680-sbx-1/mimic_iv_dataset\"\n",
    "\n",
    "# Create the SQLDatabase instance\n",
    "db = SQLDatabase.from_uri(connection_string)\n",
    "\n",
    "# Create the SQLDatabaseChain\n",
    "chain = SQLDatabaseChain(llm=llm, database=db)\n",
    "\n",
    "# Define your natural language query\n",
    "natural_language_query = \"List of medication in discharge text where patients are treated for post op limit 2\"\n",
    "\n",
    "# Generate SQL and execute\n",
    "sql_query = chain.run(natural_language_query)\n",
    "print(\"Generated SQL:\", sql_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bad351fa-b2f7-4566-b8f5-8068d627b62a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " CHF (congestive heart failure) and critical aortic stenosis are not medications, they are medical conditions. Vioxx is a medication, but it is not used to treat post-operative pain. It is a non-steroidal anti-inflammatory drug (NSAID) that was used to treat arthritis and other chronic pain conditions. However, it was withdrawn from the market in 2004 due to concerns about its safety.\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# Example reference text\n",
    "reference_text = 'The two medications in the discharge texts where patients are treated for post op are CHF and critical aortic stenosis for the first patient and Vioxx for the second patient.'\n",
    "\n",
    "# Prepare the instance for prediction\n",
    "instance_dict = {\"content\": reference_text}\n",
    "instance = json_format.ParseDict(instance_dict, Value())\n",
    "instances = [instance]\n",
    "\n",
    "# Define parameters for the MedLM model (optional)\n",
    "parameters_dict = {\n",
    "     \"candidateCount\": 1,\n",
    "     \"maxOutputTokens\": 500,\n",
    "     \"temperature\": 0.2,\n",
    "     \"topP\": 0.8,\n",
    "     \"topK\": 40\n",
    "}\n",
    "\n",
    "\n",
    "parameters = json_format.ParseDict(parameters_dict, Value())\n",
    "# Send the prediction request to MedLM\n",
    "response = client.predict(endpoint=endpoint, instances=instances, parameters=parameters)\n",
    "\n",
    "# Extract the encoded features from the MedLM response\n",
    "encoded_reference = response.predictions\n",
    "\n",
    "for prediction in encoded_reference:\n",
    "    embeddings = prediction.get('content', None)\n",
    "    # Check if embeddings were found\n",
    "    if embeddings is not None:\n",
    "        # Convert the embeddings to a NumPy array\n",
    "        features = np.array(embeddings)\n",
    "        print(features)\n",
    "    else:\n",
    "        print(\"Embeddings not found in the response.\")\n",
    "\n",
    "\n",
    "print(type(features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "34518fd1-894a-4c21-a750-58cbebc84b63",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid dtype: str12384",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[74], line 28\u001b[0m\n\u001b[1;32m     26\u001b[0m test_reference_features_data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtile(features, (\u001b[38;5;28mlen\u001b[39m(test_input_texts), \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Generate predictions\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtest_input_text_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_reference_features_data\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Decode predictions\u001b[39;00m\n\u001b[1;32m     31\u001b[0m predicted_sequences \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(predictions, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/optree/ops.py:747\u001b[0m, in \u001b[0;36mtree_map\u001b[0;34m(func, tree, is_leaf, none_is_leaf, namespace, *rests)\u001b[0m\n\u001b[1;32m    745\u001b[0m leaves, treespec \u001b[38;5;241m=\u001b[39m _C\u001b[38;5;241m.\u001b[39mflatten(tree, is_leaf, none_is_leaf, namespace)\n\u001b[1;32m    746\u001b[0m flat_args \u001b[38;5;241m=\u001b[39m [leaves] \u001b[38;5;241m+\u001b[39m [treespec\u001b[38;5;241m.\u001b[39mflatten_up_to(r) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m rests]\n\u001b[0;32m--> 747\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtreespec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mflat_args\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid dtype: str12384"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on your test data\n",
    "# Test data\n",
    "test_input_texts = [\n",
    "    'The two medications in the discharge texts where patients are treated for post op are CHF and critical aortic stenosis for the first patient and Vioxx for the second patient',\n",
    "]\n",
    "test_reference_text = ''' CHF (congestive heart failure) and critical aortic stenosis are not medications, \n",
    "they are medical conditions. Vioxx is a medication, but it is not used to treat post-operative pain. \n",
    "It is a non-steroidal anti-inflammatory drug (NSAID) that was used to treat arthritis and other chronic pain conditions.\n",
    "However, it was withdrawn from the market in 2004 due to concerns about its safety.'''\n",
    "\n",
    "# Tokenize and pad test data\n",
    "test_input_sequences = tokenizer.texts_to_sequences(test_input_texts)\n",
    "test_input_text_data = pad_sequences(test_input_sequences, maxlen=max_length, padding='post')\n",
    "test_reference_features_data = np.tile(features, (len(test_input_texts), 1))\n",
    "\n",
    "# Tokenize the texts\n",
    "tokenizer = Tokenizer(num_words=vocab_size)\n",
    "tokenizer.fit_on_texts(test_input_texts + [test_reference_text])\n",
    "\n",
    "# Convert texts to sequences\n",
    "input_sequences = tokenizer.texts_to_sequences(test_input_texts)\n",
    "reference_sequence = tokenizer.texts_to_sequences([test_reference_text])[0]\n",
    "\n",
    "# Pad the sequences\n",
    "test_input_text_data = pad_sequences(input_sequences, maxlen=max_length, padding='post')\n",
    "test_reference_features_data = np.tile(features, (len(test_input_texts), 1))\n",
    "# Generate predictions\n",
    "predictions = model.predict([test_input_text_data, test_reference_features_data])\n",
    "\n",
    "# Decode predictions\n",
    "predicted_sequences = np.argmax(predictions, axis=1)\n",
    "predicted_texts = tokenizer.sequences_to_texts(predicted_sequences)\n",
    "\n",
    "\n",
    "# Convert strings to integers (assuming they represent numerical values)\n",
    "flat_args = [int(arg) for arg in flat_args]\n",
    "\n",
    "# Now call treespec.unflatten\n",
    "result = treespec.unflatten(map(func, *flat_args))\n",
    "\n",
    "\n",
    "# Calculate metrics\n",
    "loss, accuracy = model.evaluate(\n",
    "    [test_input_text_data, test_reference_features_data])\n",
    "    #test_target_text_data,\n",
    "\n",
    "\n",
    "# Print the results\n",
    "print(\"Loss:\", loss)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# You can also use other metrics like ROUGE score for summarization evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75155f6-bfa1-4a33-98d3-b10281b1b66d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6b4a4ebb-2c48-4e52-bc52-455feccbb452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features dtype: <U387, shape: ()\n"
     ]
    }
   ],
   "source": [
    "print(f\"features dtype: {features.dtype}, shape: {features.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292648aa-88aa-438b-9586-74a8cfe46f59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41ebd9a-f9f5-4ea2-b216-2511adbeda0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1de2866-fcf4-4372-85fe-8a4d37fe25e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1368f3e1-88bc-497a-92e5-e022e347f1fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acacd3a6-9bcc-40d1-9db4-ceffcca3b626",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e9b62d77-1626-4605-b0e2-32e68a2fb294",
   "metadata": {},
   "source": [
    "# Conclusion: Improving MedLM with Multimodal Weights\n",
    "\n",
    "- Here's how multimodal weights can improve the MedLM model:\n",
    "1. Enhanced Context: By incorporating information from multiple modalities, the model gains a richer understanding of the medical context. This can lead to more accurate predictions.\n",
    "2. Complementary Information: Different modalities often provide complementary information. For example, a medical scan might reveal a tumor, while a patient's symptoms might provide additional clues about the tumor's characteristics.\n",
    "3. Robustness: Multimodal models are often more robust to noise or missing data in a single modality.\n",
    "Example (Conceptual)\n",
    "\n",
    "If you are training a MedLM model to predict the risk of a patient developing diabetes. You could use:\n",
    "\n",
    "Text: Patient medical records, including family history, lifestyle factors, and previous diagnoses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1278bf0f-1f0a-4461-8be0-d4a82a756e47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "35db95eb-6cd1-48c3-9a47-9ca325002d13",
   "metadata": {},
   "source": [
    "# Recommendations: Challenges and Considerations\n",
    "\n",
    "Data Availability: Collecting and annotating multimodal data can be challenging and expensive.\n",
    "\n",
    "Computational Resources: Training multimodal models can require significant computational resources.\n",
    "\n",
    "Feature Engineering: Carefully selecting and engineering features from each modality is crucial for successful multimodal learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cf8133-e8c1-4f4b-b39d-fc9a7fb9e24d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": ".m123",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/:m123"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
